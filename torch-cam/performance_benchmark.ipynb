{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFzdDvjxj3UU"
      },
      "source": [
        "## Environment setup\n",
        "\n",
        "For optimal training speed, ensure to enable the GPU of Colab!\n",
        "Go to `Runtime>Change runtime type`, then select `GPU` in `Hardware accelerator` and click on `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBNEyEcMj5N3",
        "outputId": "ad71c4fc-09a5-4144-fdab-1cb75d0f13f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Oct 27 15:00:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHilmWKltS4",
        "outputId": "12980af7-fd1e-4708-f6fc-4e845b0da910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Architecture:                x86_64\n",
            "  CPU op-mode(s):            32-bit, 64-bit\n",
            "  Address sizes:             46 bits physical, 48 bits virtual\n",
            "  Byte Order:                Little Endian\n",
            "CPU(s):                      2\n",
            "  On-line CPU(s) list:       0,1\n",
            "Vendor ID:                   GenuineIntel\n",
            "  Model name:                Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:              6\n",
            "    Model:                   85\n",
            "    Thread(s) per core:      2\n",
            "    Core(s) per socket:      1\n",
            "    Socket(s):               1\n",
            "    Stepping:                3\n",
            "    BogoMIPS:                4000.44\n",
            "    Flags:                   fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pg\n",
            "                             e mca cmov pat pse36 clflush mmx fxsr sse sse2 ss h\n",
            "                             t syscall nx pdpe1gb rdtscp lm constant_tsc rep_goo\n",
            "                             d nopl xtopology nonstop_tsc cpuid tsc_known_freq p\n",
            "                             ni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2ap\n",
            "                             ic movbe popcnt aes xsave avx f16c rdrand hyperviso\n",
            "                             r lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp fs\n",
            "                             gsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invp\n",
            "                             cid rtm mpx avx512f avx512dq rdseed adx smap clflus\n",
            "                             hopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n",
            "                             c xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Virtualization features:     \n",
            "  Hypervisor vendor:         KVM\n",
            "  Virtualization type:       full\n",
            "Caches (sum of all):         \n",
            "  L1d:                       32 KiB (1 instance)\n",
            "  L1i:                       32 KiB (1 instance)\n",
            "  L2:                        1 MiB (1 instance)\n",
            "  L3:                        38.5 MiB (1 instance)\n",
            "NUMA:                        \n",
            "  NUMA node(s):              1\n",
            "  NUMA node0 CPU(s):         0,1\n",
            "Vulnerabilities:             \n",
            "  Gather data sampling:      Not affected\n",
            "  Indirect target selection: Vulnerable\n",
            "  Itlb multihit:             Not affected\n",
            "  L1tf:                      Mitigation; PTE Inversion\n",
            "  Mds:                       Vulnerable; SMT Host state unknown\n",
            "  Meltdown:                  Vulnerable\n",
            "  Mmio stale data:           Vulnerable\n",
            "  Reg file data sampling:    Not affected\n",
            "  Retbleed:                  Vulnerable\n",
            "  Spec rstack overflow:      Not affected\n",
            "  Spec store bypass:         Vulnerable\n",
            "  Spectre v1:                Vulnerable: __user pointer sanitization and usercop\n",
            "                             y barriers only; no swapgs barriers\n",
            "  Spectre v2:                Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-\n",
            "                             eIBRS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                     Not affected\n",
            "  Tsa:                       Not affected\n",
            "  Tsx async abort:           Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1JuJQsCjiH1"
      },
      "source": [
        "## Installation\n",
        "\n",
        "In this tutorial, you will need the entire project codebase. So first, we clone the project's GitHub repository and install from source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJDkDk-sjXE7",
        "outputId": "c7d56b95-2573-45ee-a288-6df4a2cb28ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'torch-cam' already exists and is not an empty directory.\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m43 packages\u001b[0m \u001b[2min 123ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.40ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mtorchcam\u001b[0m\u001b[2m==0.4.1.dev0 (from file:///content/torch-cam)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/frgfm/torch-cam.git\n",
        "!uv pip install -e 'torch-cam/.[scripts]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwNS2TFfkUNk"
      },
      "source": [
        "Now we'll download the files we need for the script to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdCkL5GVkYpe",
        "outputId": "02e921c3-f210-447b-d63e-5e4f8e066a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-27 15:00:33--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.182.103.152, 52.216.208.64, 54.231.139.24, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.182.103.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 341663724 (326M) [application/x-tar]\n",
            "Saving to: ‘imagenette2-320.tgz’\n",
            "\n",
            "imagenette2-320.tgz 100%[===================>] 325.83M  52.1MB/s    in 6.4s    \n",
            "\n",
            "2025-10-27 15:00:39 (51.0 MB/s) - ‘imagenette2-320.tgz’ saved [341663724/341663724]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\n",
        "!tar -xzf imagenette2-320.tgz\n",
        "!rm imagenette2-320.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyKbVScSlDAh"
      },
      "source": [
        "## Running the benchmark\n",
        "\n",
        "The benchmark script has many parameters for you to experiment on, you can use the help command to inspect them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZpdNtvhlEds",
        "outputId": "363ee1e8-41e3-4977-815e-96175e4a0169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: eval_perf.py [-h] [--arch ARCH] [--target TARGET] [--size SIZE]\n",
            "                    [-b BATCH_SIZE] [--device DEVICE] [-j WORKERS]\n",
            "                    data_path method\n",
            "\n",
            "CAM method performance evaluation\n",
            "\n",
            "positional arguments:\n",
            "  data_path             path to dataset folder\n",
            "  method                CAM method to use\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --arch ARCH           Name of the torchvision architecture (default:\n",
            "                        mobilenet_v3_large)\n",
            "  --target TARGET       Target layer name (default: None)\n",
            "  --size SIZE           The image input size (default: 224)\n",
            "  -b BATCH_SIZE, --batch-size BATCH_SIZE\n",
            "                        batch size (default: 32)\n",
            "  --device DEVICE       Default device to perform computation on (default:\n",
            "                        None)\n",
            "  -j WORKERS, --workers WORKERS\n",
            "                        number of data loading workers (default: 2)\n"
          ]
        }
      ],
      "source": [
        "!python torch-cam/scripts/eval_perf.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTJSv9M3l515"
      },
      "source": [
        "Now let's run the benchmark on the downloaded dataset for a given model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJu7XK_ml-xp",
        "outputId": "ef8cf1b4-e38c-4318-86fc-2c34e9f3d427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GradCAM w/ mobilenet_v3_large (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 26.78%, Increase in Confidence 34.83%, Skipped 0 samples\n",
            "GradCAMpp w/ mobilenet_v3_large (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 31.82%, Increase in Confidence 25.35%, Skipped 0 samples\n",
            "SmoothGradCAMpp w/ mobilenet_v3_large (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 26.90%, Increase in Confidence 26.78%, Skipped 0 samples\n",
            "XGradCAM w/ mobilenet_v3_large (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 26.78%, Increase in Confidence 34.83%, Skipped 0 samples\n",
            "LayerCAM w/ mobilenet_v3_large (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 25.26%, Increase in Confidence 28.82%, Skipped 0 samples\n"
          ]
        }
      ],
      "source": [
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ GradCAM --arch mobilenet_v3_large --target features\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ GradCAMpp --arch mobilenet_v3_large --target features\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ SmoothGradCAMpp --arch mobilenet_v3_large --target features\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ XGradCAM --arch mobilenet_v3_large --target features\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ LayerCAM --arch mobilenet_v3_large --target features\n",
        "\n",
        "# Other CAM methods run out of VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTWsBbl6Esk",
        "outputId": "348ef8e6-8013-46c3-a780-624dc6acf663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GradCAM w/ resnet18 (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 26.86%, Increase in Confidence 22.50%, Skipped 0 samples\n",
            "GradCAMpp w/ resnet18 (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 52.71%, Increase in Confidence 19.62%, Skipped 0 samples\n",
            "SmoothGradCAMpp w/ resnet18 (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 20.96%, Increase in Confidence 24.82%, Skipped 0 samples\n",
            "XGradCAM w/ resnet18 (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 26.86%, Increase in Confidence 22.50%, Skipped 0 samples\n",
            "LayerCAM w/ resnet18 (validation set of Imagenette on (224, 224) inputs)\n",
            "Average Drop 18.05%, Increase in Confidence 28.94%, Skipped 0 samples\n"
          ]
        }
      ],
      "source": [
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ GradCAM --arch resnet18 --target layer4\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ GradCAMpp --arch resnet18 --target layer4\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ SmoothGradCAMpp --arch resnet18 --target layer4\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ XGradCAM --arch resnet18 --target layer4\n",
        "!python torch-cam/scripts/eval_perf.py /content/imagenette2-320/ LayerCAM --arch resnet18 --target layer4\n",
        "\n",
        "# Other CAM methods run out of VRAM"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
